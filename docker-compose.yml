services:
  # Base image with CUDA support, jupyter and nvim configuration
  base:
    image: pytorch-image
    build: 
      context: . 
      dockerfile: Containerfile.base
    entrypoint: /bin/true

  # Base torch image, based on the CUDA image
  ml-pytorch:
    image: pytorch-image
    build:
      context: .
      dockerfile: Containerfile.pytorch
    ports:
      - "8888:8888"
    volumes: 
      - ./workspace:/workspace
    env_file:
      - .env
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    stdin_open: true
    tty: true
    container_name: pytorch-container
    depends_on:
      - base

