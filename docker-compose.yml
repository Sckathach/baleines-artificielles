services:
  ml-pytorch:
    build:
      context: .
      dockerfile: pytorch/Containerfile.base
    image: local/pytorch-image:latest
    ports:
      - "8888:8888"
    volumes:
      - ./workspace:/workspace
    env_file:
      - share/.env
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    stdin_open: true
    tty: true
    container_name: ml-pytorch-container

  owl-jupyter:
    build:
      context: .
      dockerfile: ocaml/Containerfile
      target: ocaml
    image: local/owl-jupyter:latest
    ports:
      - "8889:8888"
    env_file:
      - share/.env
    stdin_open: true
    tty: true
    container_name: owl-jupyter-container

  ml-jax:
    build:
      context: .
      dockerfile: Containerfile
      target: jax
    image: local/jax-image:latest
    ports:
      - "8890:8888"
    volumes:
      - ./workspace:/workspace
    env_file:
      - share/.env
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    stdin_open: true
    tty: true
    container_name: ml-jax-container
